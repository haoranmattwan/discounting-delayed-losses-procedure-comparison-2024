---
title: "Validating Efficient Methods for Measuring Intertemporal Choice"
subtitle: "A Methodological Comparison of Two Procedures for Assessing Delayed Losses"
author: "Haoran (Matt) Wan"
date: "today"
format: 
  html:
    toc: true
    code-fold: false
    self-contained: true
    theme: cosmo
    mainfont: "Garamond"
execute:
  warning: false
  message: false
engine: knitr
---

## Introduction

This document provides the complete R code to replicate the analyses from the publication:

> Wan, H., Green, L., & Myerson, J. (2024). Delayed monetary losses: Do different procedures and measures assess the same construct?. *Behavioural Processes, 222*, 105101. [https://doi.org/10.1016/j.beproc.2024.105101](https://doi.org/10.1016/j.beproc.2024.105101)

### Project Objective
The primary goal of this study is **methodological validation**. It formally tests whether a brief, 27-item survey (the Delayed Losses Questionnaire, or DLQ) provides a valid and reliable measure of delay discounting when compared to the more resource-intensive, iterative Adjusting-Amount (Adj-Amt) procedure.

### Analysis Workflow
1.  **Setup**: Loads all necessary packages and defines custom functions.
2.  **Data Processing**: Cleans and transforms the raw data, calculating four key discounting measures (two for each procedure).
3.  **Group-Level Analysis**: Visualizes aggregate choice patterns and fits non-linear models to assess data quality.
4.  **Reliability Analysis**: Examines the internal consistency of measures *within* each procedure.
5.  **Validity Analysis**: Tests the core hypothesis by correlating measures *between* the two procedures.
6.  **Choice Pattern Analysis**: Categorizes individual response styles and assesses their consistency across procedures.

The data used in this analysis are publicly available on the Open Science Framework at [https://osf.io/emb2q/](https://osf.io/emb2q/).

```{r setup}
#| message: false
#| warning: false

# --- 1. SETUP: PACKAGES, OPTIONS, AND FUNCTIONS ---

# Set global chunk options to suppress messages and warnings for a clean HTML output
knitr::opts_chunk$set(message = FALSE, warning = FALSE, error = FALSE)

# --- Load Packages ---
# Modeling & Statistics
library(minpack.lm) # For non-linear least squares fitting
library(betareg)    # For beta regression
library(multcomp)   # For general linear hypotheses
library(gmodels)    # For cross-tabulation

# Visualization
library(ggplot2)
library(ggpubr)
library(lemon)

# Data Wrangling & Core Utilities
library(tidyverse)
library(here)
library(janitor)
library(readxl)

# --- Custom Functions ---

#' Custom ggplot2 Theme for Publication-Ready Plots
#' @description A standardized theme for consistent plot aesthetics.
#' @return A ggplot theme object.
mattheme <- theme(
  text = element_text(size = 12, family = "Arial", color = "black", face = "bold"), 
  axis.text.y = element_text(colour = "black", size = 10, face = "bold"), 
  axis.text.x = element_text(colour = "black", size = 10, face = "bold", angle = 0), 
  axis.title.x = element_text(margin = margin(7, 0, 0, 0), size = 14), 
  axis.title.y = element_text(margin = margin(0, 7, 0, 0), size = 14), 
  plot.title = element_text(size = 14, face = "bold", hjust = 0.5), 
  panel.background = element_rect(fill = "white", linetype = 1, color = "black", size = 1), 
  panel.grid = element_blank(),
  strip.background = element_blank(),
  strip.text = element_text(size=10),
  legend.key = element_blank()
)

#' Area Under the Curve (AuC) Calculation
#' @description Calculates area under the curve using the trapezoidal rule.
#' @param x A numeric vector of x-coordinates (e.g., normalized delays).
#' @param y A numeric vector of y-coordinates (e.g., subjective values).
#' @return The calculated area as a single numeric value.
auc <- function(x, y) {
  sum(diff(x) * (y[-1] + y[-length(y)])) / 2
}
```

## Data Processing

This section details the entire data processing pipeline. The raw data is loaded, filtered to the final sample (N = 431), and then transformed to calculate the four primary discounting scores:
- **For the Adj-Amt procedure**:
    1. `auc_adj_amt`: Area Under the Curve (atheoretical).
    2. `logk_adj_amt`: The log-transformed *k* parameter from a simple hyperbolic model (theoretical).
- **For the DLQ procedure**:
    1. `prop_imm_dlq`: The proportion of immediate choices (atheoretical).
    2. `logk_dlq`: The log-transformed *k* parameter estimated from the choice pattern (theoretical).

Finally, individual choice patterns are classified for a subsequent consistency analysis.

```{r load_data}
# --- 2. DATA LOADING AND PROCESSING ---

# --- Load and Clean Raw Data ---
adj_amt_data <- read_excel("Data_AdjAmt_DLQ.xlsx", sheet = 1) |>
  rename(ID = `Participant Number`, Delay = `Delay (months)`) |>
  mutate(Amount = case_when(Amount == 90 ~ "$90", 
                            Amount == 240 ~ "$240", 
                            Amount == 1500 ~ "$1,500"),
         Procedure = "Adj-Amt")
dlq_data <- read_excel("Data_AdjAmt_DLQ.xlsx", sheet = 2) |>
  rename(ID = `Participant Number`, Q_ID = `Question Number`) |>
  mutate(Procedure = "DLQ")

# --- Calculate Scores for the Adjusting-Amount (Adj-Amt) Procedure ---
adj_amt_scores <- adj_amt_data |>
  group_by(Procedure, ID, Amount) |>
  summarise(
    # 1. Atheoretical measure: Area Under the Curve (AuC)
    auc_adj_amt = auc(Delay / 108, RSV),
    # 2. Theoretical measure: log(k) from a simple hyperbola
    # CORRECTED: Fit the model for k directly and then log-transform the result.
    # This is more explicit and less prone to reparameterization errors.
    logk_adj_amt = tryCatch({
      fit <- nlsLM(RSV ~ 1 / (1 + k * Delay), start = list(k = 0.01))
      log(coef(fit)[['k']])
    }, error = function(e) NA),
    .groups = 'drop'
  )

# Create a lookup table with the fixed parameters for each of the 27 DLQ items.
# This avoids hardcoding values and makes the code cleaner and less error-prone.
dlq_item_parameters <- tibble(
  Q_ID = 1:27,
  # 'k' is the discounting parameter associated with each choice item
  k = c(0.014000, 0.000057, 0.000880, 0.000057, 0.001800, 0.000140, 0.000880, 0.000022, 
        0.005900, 0.000890, 0.000022, 0.000140, 0.000140, 0.002300, 0.000009, 0.000057,
        0.014000, 0.000340, 0.000009, 0.005800, 0.005500, 0.000022, 0.002300, 0.014000, 
        0.000340, 0.000340, 0.000009),
  # Amount block for the larger, delayed reward
  Amount = c("$165", "$75", "$240", "$180", "$225", "$90", "$150", "$90", "$240", 
             "$105", "$255", "$180", "$255", "$150", "$105", "$225", "$90", "$165", 
             "$240", "$180", "$105", "$150", "$75", "$255", "$75", "$225", "$165")
) |>
  mutate(Amount = case_when(Amount %in% c("$75", "$90", "$105") ~ "$90",
                            Amount %in% c("$150", "$165", "$180") ~ "$165",
                            Amount %in% c("$225", "$240", "$255") ~ "$240"))

# --- Calculate Scores for the Delayed Losses Questionnaire (DLQ) ---
dlq_data <- dlq_data |>
  left_join(dlq_item_parameters, by = "Q_ID") |>
  mutate(k = case_when(k == 0.00088 ~ 0.00089,
                       k == 0.00180 ~ 0.00230,
                       k %in% c(0.0058, 0.0059) ~ 0.00550,
                       TRUE ~ k)) 
dlq_scores <- dlq_data |>
  group_by(Procedure, ID, Amount) |>
  summarise(
    # 1. Atheoretical measure: Proportion of immediate choices (out of 9 items)
    prop_imm_dlq = mean(Choice),
    # 2. Theoretical measure: log(k) estimated from the choice pattern
    logk_dlq = {
      choices <- Choice
      k_values <- k
      # Handle non-switching participants
      if (all(choices == 1)) {
        log(min(k_values)) # Always immediate -> largest k
      } else if (all(choices == 0)) {
        log(max(k_values)) # Always delayed -> smallest k
      } else {
        # Find k that maximizes response consistency around a switch point
        n_consistent <- sapply(k_values, function(k_level) {
          sum((choices == 0 & k_values <= k_level) | (choices == 1 & k_values >= k_level))
        })
        indifference_ks <- k_values[which(n_consistent == max(n_consistent))]
        log(prod(indifference_ks)^(1/length(indifference_ks))) # Geometric mean
      }
    },
    .groups = 'drop'
  )

# --- Classify Individual Choice Patterns ---
adj_amt_patterns <- adj_amt_data |>
  filter(Amount != "$1,500") |>
  group_by(ID, Amount) |>
  summarise(correlation = cor(RSV, log(Delay)), mean_sv = mean(RSV), .groups = 'drop') |>
  mutate(
    correlation = ifelse(is.na(correlation), 0, correlation),
    pattern = case_when(
      correlation < 0 | mean_sv == min(adj_amt_data$RSV) ~ "Typical",
      correlation > 0 ~ "Atypical",
      mean_sv == max(adj_amt_data$RSV) ~ "Always immediate"
      ),
    pattern = ifelse(is.na(pattern), "Typical", pattern)
  ) |>
  group_by(ID) |>
  summarise(pattern_adj_amt = if_else(n_distinct(pattern) == 1, first(pattern), "Inconsistent"))

dlq_patterns <- dlq_data |>
  filter(Amount != "$165") |>
  group_by(ID, Amount) |>
  summarise(correlation = cor(Choice, log(k)), mean_choice = mean(Choice), .groups = 'drop') |>
  mutate(
    correlation = if_else(is.na(correlation), 0, correlation),
    pattern = case_when(
      correlation > 0 | mean_choice == 0 ~ "Typical",
      correlation < 0 ~ "Atypical",
      mean_choice == 1 ~ "Always immediate"
    )
  ) |>
  group_by(ID) |>
  summarise(pattern_dlq = if_else(n_distinct(pattern) == 1, first(pattern), "Inconsistent"))

pattern_consistency <- full_join(adj_amt_patterns, dlq_patterns, by = "ID")

# --- Create Group-Level Dataframe for Plotting (Figure 1) ---
adj_amt_group_level <- adj_amt_data |>
  group_by(Amount, Delay) |>
  summarise(mean_RSV = mean(RSV), .groups = 'drop') |>
  mutate(Amount = factor(Amount, levels = c("$90", "$240", "$1,500")))

dlq_group_level <- dlq_data |>
  group_by(Amount, k) |>
  summarise(Prop = mean(Choice), .groups = 'drop') |>
  mutate(Amount = factor(Amount, levels = c("$90", "$165", "$240")))
```

## Group-Level Analysis

This section replicates Figure 1 from the publication, visualizing the aggregate discounting patterns for both procedures. The plots confirm that the data conform to established findings: subjective value decreases with delay (Adj-Amt), and the probability of choosing the immediate option increases with the question's *k* parameter (DLQ). Goodness-of-fit statistics confirm that the chosen non-linear models describe the data well.

```{r group_analysis}
# --- 3. GROUP-LEVEL ANALYSIS (FIGURE 1 REPLICATION) ---

# --- Plot for Adjusting-Amount Procedure ---
plot_adj_amt <- adj_amt_group_level |>
  ggplot(aes(x = Delay, y = mean_RSV, shape = Amount, color = Amount, linetype = Amount)) +
  # Fit hyperboloid discounting functions to the group means
  geom_smooth(method = "nlsLM", formula = y ~ 1 / (1 + exp(k) * x)^s, 
              method.args = list(start = list(k = -4, s = 1)), se = FALSE, size = 0.8) +
  geom_point(aes(fill = Amount), size = 4, stroke = 1) +
  scale_y_continuous(limits = c(0, 1.05), breaks = seq(0, 1, by = 0.2)) +
  scale_x_continuous(limits = c(0, 113), breaks = c(4, 18, 60, 108)) +
  scale_shape_manual(name = "Amount", values = c("$90"=21, "$240"=22, "$1,500"=24)) +
  scale_color_manual(name = "Amount", values = c("$90"="#1f78b4", "$240"="#ff7f00", "$1,500"="#33a02c")) +
  scale_fill_manual(name = "Amount", values = c("$90"="#1f78b4", "$240"="#ff7f00", "$1,500"="#33a02c")) +
  scale_linetype_manual(name = "Amount", values = c("$90"="solid", "$240"="dashed", "$1,500"="dotted")) +
  labs(x = "Delay (months)", y = "Relative Subjective Value", title = "Adjusting-Amount Procedure") +
  theme_bw() + mattheme + theme(legend.position = c(0.8, 0.25))

# --- Plot for Delayed Losses Questionnaire ---
plot_dlq <- dlq_group_level |>
  mutate(Amount = case_when(Amount == "$90" ~ "$75-105",
                            Amount == "$165" ~ "$150-180",
                            Amount == "$240" ~ "$225-255")) |>
  ggplot(aes(x = k, y = Prop, shape = Amount, color = Amount, linetype = Amount)) +
  # Fit logistic functions to the choice proportions
  geom_smooth(method = "nlsLM", formula = y ~ 1 / (1 + exp( - ( (x) - (a) ) * (r) ) ),
              method.args = list(start = list(a = -9.3, r = .58), control = list(maxiter = 1000)), 
              se = FALSE, size = 0.8) +
  geom_point(aes(fill = Amount), size = 4, stroke = 1) +
  scale_x_continuous(trans = 'log10', breaks = c(1e-5, 1e-4, 1e-3, 1e-2), labels = c("0.00001", "0.0001", "0.001", "0.01")) +
  scale_y_continuous(limits = c(0, 1.05), breaks = seq(0, 1, by = 0.2)) +
  scale_shape_manual(name = "Amount", values = c("$75-105"=21, "$150-180"=22, "$225-255"=24)) +
  scale_color_manual(name = "Amount", values = c("$75-105"="#1f78b4", "$150-180"="#ff7f00", "$225-255"="#33a02c")) +
  scale_fill_manual(name = "Amount", values = c("$75-105"="#1f78b4", "$150-180"="#ff7f00", "$225-255"="#33a02c")) +
  scale_linetype_manual(name = "Amount", values = c("$75-105"="solid", "$150-180"="dashed", "$225-255"="dotted")) +
  labs(x = expression(paste(bold("Question "), bolditalic("k"), bold(" Parameter"))), y = "Choice of Immediate Payment", title = "Delayed Losses Questionnaire") +
  theme_bw() + mattheme + theme(legend.position = c(0.2, 0.75))

# --- Arrange Plots and Display ---
ggarrange(plot_adj_amt, plot_dlq, ncol = 2)

# --- Goodness-of-Fit (R-squared) for Group-Level Models ---
cat("--- Adj-Amt: R-squared for Hyperboloid Fits ---\n")
adj_amt_r2 <- adj_amt_group_level |>
  group_by(Amount) |>
  summarise(R2 = modelr::rsquare(
    nlsLM(mean_RSV ~ 1 / (1 + exp(k) * Delay)^s, start = list(k = -4, s = 1)),
    data = pick(everything())
  ))
print(adj_amt_r2, digits = 3)

cat("\n--- DLQ:  R-squared for Logistic Fits ---\n")
dlq_r2 <- dlq_group_level |>
  group_by(Amount) |>
  summarise(R2 = modelr::rsquare(
    nlsLM(Prop ~ 1 / (1 + exp( - ( log(k) - (x) ) * (r) ) ), 
    start = list(x = -10, r = 1), control = list(maxiter = 1000)),
    data = pick(everything())
  ))
print(dlq_r2, digits = 3)
```

## Reliability and Validity Analysis

This is the core of the study. First, **reliability** is assessed by examining the correlations between different loss amounts *within* each procedure. High correlations indicate that the procedure consistently measures the same construct regardless of the specific amounts used. Second, **convergent validity** is tested by examining the correlations *between* the two procedures. High correlations would provide strong evidence that both methods are measuring the same underlying construct.

```{r reliability_validity}
# --- 4. INDIVIDUAL-LEVEL RELIABILITY AND VALIDITY ---

# --- Within-Procedure Reliability (Alternate-Forms) ---
# This assesses if the measures are consistent across different amounts.

cat("--- Reliability: Correlations Between Amounts Within Adjusting-Amount Procedure ---\n")
adj_amt_reliability_data <- adj_amt_scores |>
  pivot_longer(names_to = "measure", values_to = "score", 
               cols = c(auc_adj_amt, logk_adj_amt)) |>
  separate(measure, into = c("measure_type", "procedure"), sep = "_", extra = "merge") |>
  pivot_wider(names_from = Amount, values_from = score, names_prefix = "amount_") |>
  group_by(measure_type) |> select(5:7) 
auc_reliability_table <- filter(adj_amt_reliability_data, measure_type == "auc") |>
  ungroup() |> select(-1) |> 
  cor()
print(auc_reliability_table, digits = 3)
logk_reliability_table <- filter(adj_amt_reliability_data, measure_type == "logk") |>
  ungroup() |> select(-1) |> 
  cor()
print(logk_reliability_table, digits = 3)

cat("--- Reliability: Correlations Between Amounts Within DLQ ---\n")
dlq_reliability_data <- dlq_scores |>
  pivot_longer(names_to = "measure", values_to = "score", 
               cols = c(prop_imm_dlq, logk_dlq)) |>
  separate(measure, into = c("measure_type", "procedure"), sep = "_", extra = "merge") |>
  pivot_wider(names_from = Amount, values_from = score, names_prefix = "amount_") |>
  group_by(measure_type) |> select(5:7) 
prop_reliability_table <- filter(dlq_reliability_data, measure_type == "prop") |>
  ungroup() |> select(-1) |> 
  cor()
print(prop_reliability_table, digits = 3)
logk_reliability_table <- filter(dlq_reliability_data, measure_type == "logk") |>
  ungroup() |> select(-1) |> 
  cor()
print(logk_reliability_table, digits = 3)

# --- Within-Procedure Concurrent Validity ---
# This assesses if the atheoretical and theoretical measures capture the same information.
# The correlation should be high and negative, as higher AuC/prop_imm means steeper
# discounting, while higher logk means shallower discounting.
cat("\n--- Concurrent Validity: Correlations Between Atheoretical and Theoretical Measures ---\n")
adj_amt_concurrent_validity <- adj_amt_scores |>
  group_by(Amount) |>
  summarise(Adj_Amt_Corr = cor(auc_adj_amt, logk_adj_amt, use = "pairwise.complete.obs"), .groups = 'drop')
print(adj_amt_concurrent_validity, digits = 3)

dlq_concurrent_validity <- dlq_scores |>
  group_by(Amount) |>
  summarise(DLQ_Corr = cor(prop_imm_dlq, logk_dlq, use = "pairwise.complete.obs"), .groups = 'drop')
print(dlq_concurrent_validity, digits = 3)

# --- Between-Procedure Convergent Validity (Main Result) ---
cat("\n--- Convergent Validity: Correlations Between Procedures (Main Result) ---\n")
convergent_validity_table <- full_join(
    filter(adj_amt_scores, Amount != "$1,500")[,-1],
    filter(dlq_scores, Amount != "$165")[,-1]
  ) |>
  group_by(Amount) |>
  summarise(atheoretical_correlation = cor(auc_adj_amt, prop_imm_dlq),
            theoretical_correlation = cor(logk_adj_amt, logk_dlq))
print(convergent_validity_table, digits = 3)
```

## Analysis of Choice Patterns

Finally, this section examines whether individuals show consistent *qualitative* patterns of choice across the two procedures. Participants are classified based on their response styles, and a contingency table analysis is used to test if a participant's classification on one procedure is significantly associated with their classification on the other.

```{r choice_pattern}
# --- 5. ANALYSIS OF CHOICE PATTERNS ---

# --- Frequencies of Choice Patterns by Procedure ---
cat("--- Frequencies of Choice Patterns by Procedure ---\n")
pattern_summary <- pattern_consistency |>
  pivot_longer(cols = c(pattern_adj_amt, pattern_dlq), names_to = "procedure", values_to = "pattern") |>
  mutate(procedure = str_remove(procedure, "pattern_")) |>
  group_by(procedure) |>
  count(pattern) |>
  mutate(proportion = n / sum(n))
print(pattern_summary, n=10)

# --- Contingency Table of Choice Patterns (Adj-Amt vs. DLQ) ---
# This cross-tabulation shows how many participants were classified in each
# combination of categories across the two procedures.
cat("\n--- Cross-Tabulation of Choice Patterns (Observed Counts) ---\n")
contingency_table <- table(
  `Adj-Amt` = pattern_consistency$pattern_adj_amt, 
  `DLQ` = pattern_consistency$pattern_dlq
)
print(contingency_table)

# --- Formal Chi-Squared Test for Association ---
# This tests if the number of people showing consistent patterns is greater than chance.
cat("\n--- Cross-Tabulation with Chi-Squared Test ---\n")
CrossTable(
  pattern_consistency$pattern_adj_amt, 
  pattern_consistency$pattern_dlq,
  expected = TRUE, 
  chisq = TRUE, 
  format = "SPSS"
)
```